# HSDSF‑FusionBench‑Sim + Uncertainty‑Gated Fusion  
## A monolithic report and implementation guide for a simulator‑first, ICML‑grade multimodal fusion project

---

## Executive summary

This document specifies an end‑to‑end, simulator‑first research and engineering program that produces:

1) **HSDSF‑FusionBench‑Sim**: a reproducible benchmark where the atomic unit is **(binary build, runtime run)**, with **run‑level splits** designed to measure robustness under **distribution shift**.

2) **Uncertainty‑Gated Fusion (UGF)**: an interpretable mixture‑of‑experts fusion method that combines:
- a **static binary risk prior** \(p_s\) and uncertainty \(u_s\), and  
- a **dynamic online telemetry detector** \(p_d(t)\) and uncertainty \(u_d(t)\),  
with a learned gate \(g(t)\) driven by uncertainty and meta/context.

3) A **reproducible artifact**: deterministic splits, cached static outputs, one command that regenerates all tables/figures, and evaluation using **security‑meaningful metrics** (FAR/h, time‑to‑detect, event‑F1), plus calibration and uncertainty tests.

The core publishable claim is that **UGF improves reliability and early detection under distribution shift** by adapting trust between modalities using **calibrated uncertainty**, outperforming unimodal methods and conventional fusion baselines.

---

## 1. Research objective and formal problem statement

### 1.1 Thesis (the claim)
UGF improves detection reliability under distribution shift by routing trust between static and dynamic experts as their calibrated uncertainty changes.

UGF is positioned as a mixture‑of‑experts style fusion method in the spirit of classical MoE work [Jacobs et al., 1991; Jordan & Jacobs, 1994], with modern uncertainty estimation via ensembles or MC dropout [Lakshminarayanan et al., 2017; Gal & Ghahramani, 2016] and post‑hoc calibration [Guo et al., 2017].

### 1.2 Main task: online event detection
At time window \(t\):

- Static input (per binary): \(x_s\)  
- Dynamic input (per window): \(x_d^{(t)}\)  

Predict:
\[
p_f(t) = P(y_t=1 \mid x_s, x_d^{(t)})
\]
where \(y_t = 1\) indicates Trojan activation is present in the window.

### 1.3 Optional auxiliary task: binary risk scoring
Static binary scoring:
\[
p_s = P(y=1 \mid x_s)
\]
where \(y=1\) indicates a binary contains Trojan logic.

This auxiliary task yields an interpretable narrative:
- static expert provides a **prior suspicion** about a binary,
- dynamic expert provides **runtime evidence**, and
- fusion resolves conflicts under shift via uncertainty.

---

## 2. System overview

### 2.1 Modalities
- **Static modality**: deterministic binary features + optional cached embeddings/structured findings.
- **Dynamic modality**: time‑series telemetry windows generated by a TDG‑aligned simulator (and optionally real device validation).

### 2.2 Fusion method: Uncertainty‑Gated Fusion
Two experts produce calibrated predictions and uncertainties:

- Static expert:
  \[
  p_s = P(y=1 \mid x_s),\quad u_s = U_s(x_s)
  \]
- Dynamic expert:
  \[
  p_d(t) = P(y_t=1 \mid x_d^{(t)}),\quad u_d(t)=U_d(x_d^{(t)})
  \]

A gate \(g(t)\in[0,1]\) uses uncertainty and meta/context:
\[
g(t)=\sigma\left(f_\theta([u_s, u_d(t), m(t)])\right)
\]

Fusion is a convex mixture:
\[
p_f(t)=g(t)p_d(t)+(1-g(t))p_s
\]

The scientific mechanism that must be demonstrated is:

- under OOD shift, \(u_d(t)\) increases,
- the gate decreases \(g(t)\),
- the fused model maintains lower false alarm rates for comparable detection delay.

---

## 3. Non‑negotiable protocol rules

1) **No random window splits.** Splits are run‑level: unseen workload family, unseen Trojan family, unseen regime.

2) **Strong unimodal baselines.** Static‑only and dynamic‑only must be competent.

3) **Uncertainty must be predictive and calibrated.** “LLM confidence” is not acceptable. Use deep ensembles or MC dropout, and apply temperature scaling calibration [Guo et al., 2017].

4) **Gate must not cheat.** Initially, the gate must not ingest raw telemetry windows; it must operate on uncertainties and meta/context to preserve interpretability and avoid “second classifier” criticism.

5) **Security‑meaningful metrics.** Report FAR/h, time‑to‑detect, event‑level F1, and calibration metrics; ROC AUC alone is insufficient.

---

## 4. Repository and artifact structure

A paper‑grade layout:

```
hsdsf/
  simulator/
    jetson_sim.py
    schemas/telemetry_schema.md
    tests/test_schema_validate.py
    tests/test_determinism.py

  data/
    fusionbench_sim/
      binaries/
        binaries.csv
        static_features.parquet
      runs/
        run_000001/telemetry.csv
        run_000001/meta.json
        run_000001/intervals.csv
      splits/
        unseen_workload.json
        unseen_trojan.json
        unseen_regime.json

  static/
    extract_static.py
    features/deterministic_elf.py
    features/llm_structured.py
    train_static.py
    uncertainty_static.py
    calibrate_static.py

  dynamic/
    preprocess.py
    models/lstm_ae.py
    models/tcn.py
    train_dynamic.py
    uncertainty_dynamic.py
    calibrate_dynamic.py

  fusion/
    baselines.py
    gate_model.py
    train_fusion.py
    eval_fusion.py
    explain.py

  evaluation/
    labels.py
    events.py
    metrics.py
    bootstrap.py
    plots.py

  experiments/
    configs/*.yaml
    run_all.sh

  docs/
    dataset_card.md
    threat_model.md
    reproduction.md
    model_cards.md
    telemetry_schema.md

  paper/
    figures/
    tables/
```

Caching rule: every LLM/embedding output is cached by content hash; prompts and model IDs are versioned.

---

## 5. Canonical telemetry schema: the project’s data contract

### 5.1 Schema definition
A single canonical CSV row schema must be produced by all collectors (simulator and any real device pipeline). This eliminates “sim vs real branching” in the ML pipeline.

**Required columns**

**Time**
- `t_unix_s`
- `t_sim_s` (sim time; on real device this can be `t_unix_s - t0`)

**Identity**
- `run_id`
- `binary_id`

**Labels / categories**
- `mode` (idle/normal/trojan)
- `trojan_active` (0/1)
- `workload_family`
- `workload_variant`
- `trojan_family`
- `trojan_variant`

**Regime/meta**
- `power_mode` (30W/MAXN)
- `ambient_c`
- `input_voltage_v`
- `jetson_clocks` (0/1)

**Util/freq**
- `cpu_util_avg`, `cpu_util_max`, `gpu_util`, `emc_util`, `cv_util`
- `cpu_freq_mhz`, `gpu_freq_mhz`, `emc_freq_mhz`

**Temps/fan**
- `temp_cpu_c`, `temp_gpu_c`, `temp_aux_c`, `temp_ttp_c`, `temp_board_c`, `fan_est_temp_c`
- `fan_pwm`, `fan_rpm`, `hysteresis_state`

**Power rails (mW)**
- `p_sys5v_mw`, `p_cpu_mw`, `p_gpu_mw`, `p_soc_mw`, `p_cv_mw`, `p_vddrq_mw`

**Perf deltas**
- `delta_cycles`, `delta_instructions`, `delta_cache_misses`, `delta_context_switches`, `delta_page_faults`, …

**Staleness/missingness masks** (critical)
For each sensor group, define:
- `mask_temp_cpu`, `mask_temp_gpu`, `mask_temp_aux`, `mask_temp_ttp`, `mask_temp_board`
- `mask_power_cpu`, `mask_power_gpu`, `mask_power_soc`, `mask_power_cv`, `mask_power_vddrq`, `mask_power_sys5v`
- `mask_perf_cycles`, etc., if perf multiplexing is simulated

Mask semantics:
- `1` = fresh sample (updated this tick)
- `0` = stale/reused/missing

This design is necessary because the simulator already implements sensor staleness (via cached reuse). Exposing masks makes “meta‑context” real and measurable for the fusion gate.

### 5.2 Schema validator
A validator script is mandatory:
- checks required columns exist,
- verifies units/ranges (e.g., temps in \([-10, 120]\), util \([0,100]\), pwm \([0,255]\), power ≥ 0),
- verifies masks ∈ {0,1},
- ensures monotonic time progression.

---

## 6. Simulator‑first benchmark: HSDSF‑FusionBench‑Sim

### 6.1 Benchmark unit and directory layout
The atomic unit is **(binary, run)**. Each run directory contains:

- `telemetry.csv` (canonical schema)
- `meta.json` (full configuration and provenance)
- `intervals.csv` (ground truth activation intervals)

Layout:

```
data/fusionbench_sim/
  binaries/
    binaries.csv
    static_features.parquet
  runs/
    run_000001/
      telemetry.csv
      meta.json
      intervals.csv
  splits/
    unseen_workload.json
    unseen_trojan.json
    unseen_regime.json
```

### 6.2 Required `meta.json` contents
`meta.json` must include:
- `run_id`, `binary_id`
- workload descriptors: `workload_family`, `workload_variant`
- Trojan descriptors: `trojan_family`, `trojan_variant`, strength/duty parameters
- regime: `power_mode`, `ambient_c`, `input_voltage_v`, `jetson_clocks`
- simulator version identifier (git hash or explicit version string)
- full simulator configuration (serialized)
- sampled domain randomization parameters (`device_instance`)
- seed(s)

### 6.3 Ground truth intervals (`intervals.csv`)
Even if `trojan_active` exists per sample, explicit intervals are required for event metrics.

Columns:
- `t_start_sim_s`, `t_end_sim_s`
- `trojan_family`, `trojan_variant`
- `trojan_strength`, `trojan_period_s`, `trojan_on_s`

---

## 7. Required simulator upgrades (mapped to the provided code)

The simulator codebase is already TDG‑aligned in thermal, INA averaging, fan hysteresis, and throttling behavior. To become a research‑grade data factory, it must add determinism, fast generation, workload diversity, and explicit masks.

### 7.1 Deterministic fast‑forward mode
**Current behavior:** `XavierTDGModel.step()` derives `dt` from wall clock (`now_s()`), clamps it, and `SimServer.run_loop` sleeps to enforce cadence. This prevents:
- deterministic replay,
- fast generation,
- sim‑time‑based staleness.

**Required change:** refactor stepping so the model advances with explicit `dt` and maintains its own `t_sim_s`.

Implementation specification:
- Add `self.t_sim_s` to `XavierTDGModel` internal state.
- Replace `step(self)` with `step_dt(self, dt: float, t_unix_s: float)`.
- Remove wall‑clock derived `t_sim`; instead increment `self.t_sim_s += dt`.

Then in `SimServer.run_loop`:
- if `fast` mode is enabled, use fixed `dt = 1/hz` and do not sleep,
- else use wall‑clock `dt` but still advance `t_sim_s` deterministically from measured dt.

For reproducible timestamps:
- optionally set `t_unix_s = start_unix_s + t_sim_s` in fast mode.

### 7.2 Workload families as first‑class regimes
**Current behavior:** utilization dynamics are mostly determined by `mode` and a frame wave, plus background spikes.

**Required change:** introduce `workload_family` and `workload_variant` in `SimConfig`, and branch `_apply_util_dynamics()` based on them such that correlation structure differs, not only means.

Minimum families:
- `inference_periodic` (current frame wave)
- `streaming_steady_gpu` (smoother GPU, lower CPU bursts)
- `memory_bound` (high EMC, lower IPC, higher cache misses)
- `network_bursty` (context switches/page faults burst patterns)
- `cv_heavy` (CV rail dominates; AUX responds differently)

Acceptance criterion for “meaningful difference”:
- cross‑feature correlations (e.g., corr(EMC util, cache misses), corr(GPU util, p_gpu)) differ across families,
- a dynamic classifier trained on some families measurably degrades on a held‑out family (OOD effect exists).

### 7.3 Staleness/missingness masks
**Current behavior:** `SimServer._apply_sensor_staleness()` reuses cached values based on time since last update, but does not record staleness.

**Required change:** augment `_apply_sensor_staleness()` to emit mask keys.

Implementation specification:
- Add `self._mask_cache: Dict[str, int]` to `SimServer`.
- For each sensor key:
  - if updated this tick: `mask_key = 1`
  - if reused cached: `mask_key = 0`
- Include mask fields in the telemetry JSON snapshot returned by `/v1/telemetry`.
- Update `cmd_collect()` to write mask columns into CSV.

Important: once fast mode is added, staleness decisions must be based on **sim time** rather than wall time (`now_s()`), otherwise fast mode will incorrectly mark everything as “fresh”.

### 7.4 Domain randomization device instances
Add per‑run randomization to simulate device‑to‑device variability and support sim→real plausibility.

Specification:
- sample per‑run multipliers/offsets (thermal taus, theta, sensor biases, fan effectiveness, leakage scaling),
- apply them to `SimConfig` before the run begins,
- store the sampled values in `meta.json`.

Domain randomization is a standard approach for transfer robustness [Tobin et al., 2017].

### 7.5 Benign confounders and faults
To stress FAR/h and demonstrate UGF’s robustness:
- add benign thermal throttling events without Trojan (e.g., transient ambient increase or fan effectiveness decrease),
- add sensor dropout or perf multiplexing (missing perf events for intervals).

These features create realistic “dynamic confusion” where uncertainty should increase and the gate should shift weight toward the static prior.

### 7.6 Collector schema alignment (`cmd_collect`)
`cmd_collect()` currently writes a partial schema (label/mode/trojan_active/util/freq/temps/power/perf totals/deltas). It must be expanded to:
- include identity/regime fields,
- include mask columns,
- include workload/trojan family descriptors.

---

## 8. Run generation orchestration

A benchmark generator script is mandatory. It must:

- enumerate an experiment grid over:
  - workload families/variants,
  - power modes and ambient ranges,
  - Trojan families/strengths/duty cycles,
  - benign confounders,
  - device instances (domain randomization).
- produce:
  - run directories with `telemetry.csv`, `meta.json`, `intervals.csv`,
  - split manifests as JSON.

Preferred generation mode for scale:
- run generation directly in‑process by stepping the simulator model and writing CSV (HTTP polling is reserved for debugging/interactive use).

---

## 9. Hard split protocols

Three split types are required, each at run‑level:

1) **Unseen workload family**
- train on a subset of workload families,
- test on held‑out family.

2) **Unseen Trojan family**
- train on a subset of Trojan styles,
- test on held‑out style.

3) **Unseen regime**
- shift in power mode, ambient/thermal regime, or other operating regime parameters.

Split manifest format:
```json
{
  "train_runs": ["run_..."],
  "val_runs":   ["run_..."],
  "test_runs":  ["run_..."],
  "notes": "unseen_workload=cv_heavy"
}
```

---

## 10. Dynamic preprocessing pipeline (backend‑agnostic)

A single preprocessing path must support simulator CSV and real telemetry CSV.

Pipeline steps:

1) Validate schema
2) Sort and resample to fixed cadence
3) Derived features:
   - IPC: `delta_instructions / max(delta_cycles, eps)`
   - miss rates: `delta_cache_misses / max(delta_instructions, eps)`
   - power ratios: `p_gpu_mw / max(p_sys5v_mw, eps)` etc.
   - throttling indicators: frequency ratios
4) Missingness masks are concatenated as channels
5) Train‑only normalization; save scaler
6) Windowing:
   - window length \(L\) seconds,
   - stride \(S\) seconds,
   - store mapping `(run_id, t_center)` for evaluation/plots.

Outputs:
- `windows_train.npz`, `windows_val.npz`, `windows_test.npz`
- `features.json`
- `scaler.json` or `scaler.pkl`

---

## 11. Event labeling and event‑level evaluation utilities

### 11.1 Window label creation
Given `intervals.csv`, define window label \(y_t\) by overlap:
- \(y_t=1\) if overlap between window and any interval exceeds threshold (e.g., 50%).

### 11.2 Predicted events
Convert window‑level alerts to event intervals by merging contiguous positive windows.

### 11.3 Primary metrics
- **False alarms per hour (FAR/h)** computed on long benign runs.
- **Time‑to‑Detect (TTD)**: delay from interval start to first alert.
- **Event‑F1**: match predicted intervals to ground truth intervals by IoU or hit‑within‑delay.

### 11.4 Calibration and uncertainty metrics
- reliability diagrams and ECE for \(p_s, p_d, p_f\) [Guo et al., 2017]
- uncertainty shift tests: compare distribution of \(u_d\) on ID vs OOD
- risk‑coverage curve: error as a function of coverage when rejecting high‑uncertainty samples

### 11.5 Statistical confidence
Bootstrap confidence intervals over **runs**, not windows.

---

## 12. Static expert: reproducible binary prior

### 12.1 Feature sets
**Mandatory deterministic features**
- ELF section sizes, flags, entropy
- imports/symbols (hashed counts)
- strings (URLs, IPs, paths, suspicious tokens)
- basic statistics (counts, lengths)
- optional control‑flow proxies if available

**Optional learned embeddings**
- cached by content hash; versioned

**Optional LLM structured fields**
- only if cached and reproducible

### 12.2 Static model and uncertainty
- model: GBDT or MLP producing \(p_s\)
- uncertainty \(u_s\):
  - deep ensembles variance (preferred) [Lakshminarayanan et al., 2017]
  - entropy of calibrated \(p_s\)
  - disagreement between deterministic model and embedding model

### 12.3 Calibration
Temperature scaling and ECE reporting [Guo et al., 2017]. Store the temperature and calibration artifacts.

---

## 13. Dynamic expert: online telemetry detector

### 13.1 Required baselines
- **LSTM autoencoder** reconstruction score (existing baseline)
- **Discriminative temporal model** (recommended: TCN/1D CNN) producing \(p_d(t)\)

### 13.2 Uncertainty \(u_d(t)\)
Preferred approach:
- **Deep ensembles** trained with different seeds/bootstraps [Lakshminarayanan et al., 2017]
- uncertainty from ensemble variance and predictive entropy

Fallback:
- **MC dropout** stochastic forward passes [Gal & Ghahramani, 2016]

### 13.3 Calibration
Apply temperature scaling to logits and report ECE [Guo et al., 2017].

---

## 14. Fusion: UGF, baselines, and training

### 14.1 Fusion baselines (must be included)
- static‑only: \(p_s\)
- dynamic‑only: \(p_d(t)\)
- late fusion: logistic regression on \([p_s, p_d(t)]\)
- product‑of‑experts/logit‑add
- heuristic uncertainty gate: \(g=\exp(-\alpha u_d)\)

### 14.2 UGF gate inputs
Gate input vector:
- \(u_s\), \(u_d(t)\)
- meta/context \(m(t)\) (mask summaries and regime bins)

Raw telemetry must not be input to the gate in the main method; it can appear only as an ablation.

### 14.3 Stagewise training
1) Train static expert, compute \(p_s\), \(u_s\)
2) Train dynamic expert ensemble, compute \(p_d(t)\), \(u_d(t)\)
3) Calibrate both experts
4) Freeze experts; train gate parameters \(\theta\) on window labels with BCE loss on \(p_f(t)\)

Optional narrative‑consistent regularizer:
- penalize gate increasing with dynamic uncertainty (encourages \(u_d\uparrow \Rightarrow g\downarrow\)).

---

## 15. Experiment matrix and deliverables

### 15.1 Main table (per split type)
Rows: methods (static, dynamic, late fusion, PoE, heuristic gate, UGF)  
Columns:
- FAR/h at a fixed operating point
- TTD median and P90
- event‑F1
- PR‑AUC (window‑level)
- ECE

Report for each split:
- unseen workload family
- unseen Trojan family
- unseen regime

### 15.2 Key ablations
- gate inputs: \(u_d\) only vs \(u_d+u_s\) vs \(u_d+meta\) vs all
- uncertainty method: entropy vs MC dropout vs deep ensembles
- with vs without calibration
- window length/stride sensitivity
- Trojan strength/duty sweeps (including low‑and‑slow)

### 15.3 Signature figures
- FAR/h vs TTD curves for dynamic‑only vs UGF under OOD
- gate vs uncertainty plots (ID vs OOD)
- timeline plot: intervals, \(p_s\), \(p_d\), \(u_d\), \(g\), \(p_f\)

---

## 16. Reproducibility: deterministic “paper repo” behavior

### 16.1 Determinism
- fixed seeds for simulator runs, training, and splits
- split manifests committed
- cached static outputs keyed by binary hash
- no random window shuffling in test evaluation

### 16.2 One‑command reproduction
`experiments/run_all.sh` must:
1) generate sim runs
2) preprocess telemetry
3) extract static features (cached)
4) train static ensemble + calibrate
5) train dynamic ensemble + calibrate
6) train fusion gate
7) evaluate on all splits with bootstrap CIs
8) write tables/figures to `paper/`

---

## 17. Paper structure aligned with artifacts

1) Introduction  
2) Threat model and tasks  
3) HSDSF‑FusionBench‑Sim dataset and split protocol  
4) UGF method (experts, uncertainty, calibration, gate, fusion)  
5) Experiments (baselines, metrics, training details)  
6) Results (tables + ablations + figures demonstrating the mechanism)  
7) Deployment/overhead (optional)  
8) Limitations and ethics  
9) Conclusion  

---

## 18. Safety and release strategy

If releasing Trojan binaries is sensitive:
- release feature dumps and build scripts to reproduce variants locally,
- or release non‑deployable synthetic variants,
- include a misuse statement and intended‑use scope in the dataset card.

---

## 19. Core references

- Jacobs, R. A., Jordan, M. I., Nowlan, S. J., & Hinton, G. E. “Adaptive Mixtures of Local Experts.” *Neural Computation*, 1991. https://doi.org/10.1162/neco.1991.3.1.79  
- Jordan, M. I., & Jacobs, R. A. “Hierarchical Mixtures of Experts and the EM Algorithm.” *Neural Computation*, 1994. https://doi.org/10.1162/neco.1994.6.2.181  
- Guo, C., Pleiss, G., Sun, Y., & Weinberger, K. Q. “On Calibration of Modern Neural Networks.” *ICML*, 2017. https://arxiv.org/abs/1706.04599  
- Lakshminarayanan, B., Pritzel, A., & Blundell, C. “Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles.” *NeurIPS*, 2017. https://arxiv.org/abs/1612.01474  
- Gal, Y., & Ghahramani, Z. “Dropout as a Bayesian Approximation.” *ICML*, 2016. https://arxiv.org/abs/1506.02142  
- Tobin, J. et al. “Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World.” *IROS*, 2017. https://arxiv.org/abs/1703.06907  

---

## Appendix A: Simulator code change map (implementation‑oriented)

This appendix ties required benchmark features to the provided simulator code.

### A.1 Fast deterministic stepping
**Files/classes**
- `XavierTDGModel`
- `SimServer.run_loop`

**Current pattern**
- `XavierTDGModel.step()` derives dt from `now_s()`
- `SimServer.run_loop` sleeps for cadence

**Required pattern**
- `XavierTDGModel.step_dt(dt, t_unix_s)` consumes dt and advances `t_sim_s`
- `SimServer.run_loop` selects dt and optionally omits sleep (fast mode)
- staleness logic uses sim time

### A.2 Staleness masks
**Files/classes**
- `SimServer._apply_sensor_staleness`
- HTTP `/v1/telemetry`
- `cmd_collect`

**Required behavior**
- for each staled key, emit `mask_* = 0` and set value to cached (or NaN, but documented)
- for each updated key, emit `mask_* = 1`

### A.3 Collector schema expansion
**Files/functions**
- `cmd_collect`

**Required behavior**
- add identity/regime fields to CSV header/rows
- add mask fields to header/rows

### A.4 Workload families
**Files/functions**
- `SimConfig` add `workload_family`, `workload_variant`
- `_apply_util_dynamics` branches by family

---

